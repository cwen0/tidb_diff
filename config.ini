[diff]
src.instance = mysql://root@127.0.0.1:4000
dst.instance = mysql://root@127.0.0.1:63441
# dbs 和 tables 参数必须指定一个，且不能同时指定
# dbs: 数据库模式匹配，支持 LIKE 模式（如 test%）
# tables: 指定要对比的表，格式为 db1.tb1, db2.tb2
# 当指定 tables 时，只对比指定的表；当指定 dbs 时，对比匹配数据库的所有表
# dbs = test
tables = test.bank1
ignore_tables = tmp_log, sys_history, tidb_cdc.sync_point_v1
threshold = 0
output = diff_result.csv

# 对比内容：rows(逐表行数), tables(库级表数), indexes(库级索引数), views(库级视图数)
# 留空或不填则默认全部启用
compare = rows,tables,indexes,views

# 数据库级别并发数（同时处理多个数据库）
# 程序默认（未配置时）：5（偏多库场景的吞吐）
# 建议范围：1-20（生产环境建议从 1 开始逐步加，并观察 TiDB 的 QPS/CPU/连接数）
# - 少量库（<10）：1-5
# - 中等库（10-50）：5-10
# - 大量库（>50）：10-20
# 注意：
# - 每个数据库会同时连接源库+目标库（2 个连接池），请确保 max_open_conns 足够
# - 当 use_stats=false 时还会叠加表级并发，整体压力更大（见 table_concurrency 注释）
concurrency = 1

# 是否使用统计信息快速获取行数
# 程序默认（未配置时）：false
# - false：对每张表执行精确 COUNT(1)（默认，慢/重，但结果准确，可配表级并发 table_concurrency）
# - true：读取 INFORMATION_SCHEMA.TABLES.TABLE_ROWS（快，但可能不够精确）
use_stats = false

# 表级别并发数（仅当 use_stats=false 时有效）
# 程序默认（未配置时）：30（偏多表场景的吞吐）
# 建议范围：1-50（从小到大逐步加，避免把上下游 TiDB 打满）
# - 少量表（<100）：10-20
# - 中等表（100-500）：20-30
# - 大量表（500-1000）：30-40
# - 超大量表（>1000）：40-50
# 注意（仅粗略估算，实际上还受连接池/SQL 执行时间影响）：
# - 单个数据库：源库和目标库会并行 COUNT，实际并发上限约为 table_concurrency * 2
# - 多数据库：数据库之间也会并行，整体并发上限约为 concurrency * table_concurrency * 2
table_concurrency = 1

# 连接池配置（针对多库多表大表场景优化）
# max_open_conns: 最大打开连接数
# 如果未配置，将根据 concurrency 和 table_concurrency 自动计算：
#   公式：concurrency * 2 * (table_concurrency + 10)
#   最小值：1（不再强制上限，请结合实例允许的最大连接数自行评估）
# 手动配置建议（可按需超过 500，仅供起步参考）：
# - 少量库表：100-150
# - 中等库表：150-250
# - 大量库表：250-400
# - 超大量库表：400-600+
# 注意：每个数据库需要 2 个连接池（源+目标），请确保连接数足够
max_open_conns = 0

# max_idle_conns: 最大空闲连接数
# 如果未配置，将自动计算为 max_open_conns 的 80%（最小 1）
# 保持连接池热状态，减少连接建立开销
max_idle_conns = 0

# conn_max_lifetime_minutes: 连接最大生存时间（分钟），大表场景默认 30 分钟
# 设置为 0 表示不限制连接生存时间（不推荐，可能导致使用过期连接）
# 对于超大表查询，建议设置为 30-60 分钟，避免连接在长时间查询过程中过期
conn_max_lifetime_minutes = 30

# query_timeout_seconds: 单个查询超时时间（秒），0 表示使用默认值（10分钟）
# 对于超大表 COUNT(1) 查询，可能需要较长时间，建议根据表大小设置
# 例如：千万级表建议 600-1800 秒（10-30分钟），亿级表建议 1800-3600 秒（30-60分钟）
# 设置为 0 时，默认使用 10 分钟超时（避免查询时间过长导致程序卡住）
# 【重要】建议根据最大表的大小显式设置此值，避免使用默认值
# 【注意】如果程序正常结束后阻塞，请检查此配置是否合理，建议显式设置而非使用默认值
query_timeout_seconds = 0

# read_timeout_seconds: 读取超时时间（秒），0 表示使用默认值
# 针对大表查询，建议设置为 query_timeout_seconds + 60，确保有足够时间读取数据
read_timeout_seconds = 0

# write_timeout_seconds: 写入超时时间（秒），0 表示使用默认值
# 通常设置为 30-60 秒即可
write_timeout_seconds = 0

# max_execution_time_ms: 连接建立后设置 session 级的 MAX_EXECUTION_TIME（毫秒）
# 设置为 0 表示不限制；建议与 query_timeout_seconds 搭配使用，避免单条查询无限执行
max_execution_time_ms = 0

# max_retries: 查询重试次数（针对大表查询失败场景）
# 默认 2 次，范围 0-5
# 对于网络不稳定的环境，可以设置为 3-5
max_retries = 2

# snapshot_ts: TiDB 快照时间戳（可选，用于对比历史数据）
# 
# 【重要前提条件 - 必须满足】
# 使用 src.snapshot_ts 和 dst.snapshot_ts 的前提条件是 TiCDC 开启了 sync_point 功能
# 需要在 TiCDC 配置中启用：enable-sync-point = true
# 如果不开启 sync_point，无法获取准确的同步点 TSO 对，可能导致对比结果不准确
#
# 使用场景：
# 1. 在数据迁移/同步过程中对比特定时间点的数据一致性
# 2. 对比历史时间点的数据状态
# 3. 验证 CDC 同步过程中数据的一致性
# 
# 获取 snapshot_ts 的方法（必须使用 CDC sync_point）：
# 【推荐方法】通过 TiCDC sync_point 获取（前提：已开启 sync_point 功能）：
# 在下游集群执行：
# SELECT * FROM tidb_cdc.syncpoint_v1 ORDER BY created_at DESC LIMIT 1\G
# 
# 返回结果示例：
# ***************************[ 1. row ]***************************
# ticdc_cluster_id | default
# changefeed       | default/test
# primary_ts       | 462798819164160000    # 源库的 TSO，用于 src.snapshot_ts
# secondary_ts     | 462798819559997443    # 下游的 TSO，用于 dst.snapshot_ts
# created_at       | 2025-12-11 15:16:31
# 
# 字段说明：
# - primary_ts: 源库（上游）的 TSO，对应配置中的 src.snapshot_ts
# - secondary_ts: 下游集群的 TSO，对应配置中的 dst.snapshot_ts
# - 这两个 TSO 代表同一逻辑时间点在不同集群的快照，确保数据一致性对比的准确性
#
# 配置说明：
# - src.snapshot_ts: 源库使用的快照时间戳（19位整数）
#   - 使用 CDC sync_point 获取的 primary_ts 值
# - dst.snapshot_ts: 目标库使用的快照时间戳（19位整数）
#   - 使用 CDC sync_point 获取的 secondary_ts 值
# - 建议同时配置 src 和 dst，确保对比同一逻辑时间点的数据
# - 如果配置了 snapshot_ts，工具会在连接后自动设置 SET @@tidb_snapshot=?
# - 注意：使用 snapshot_ts 时，查询的是历史快照数据，不是实时数据
# - 重要：必须使用 CDC sync_point 获取的 TSO 对，才能确保对比的是同一逻辑时间点的数据
#
# 示例（使用 CDC sync_point 获取的值）：
src.snapshot_ts = 462979423272960000  # primary_ts（源库的 TSO）
dst.snapshot_ts = 462979423729090737  # secondary_ts（下游的 TSO）